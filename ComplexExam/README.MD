# Complex Exam

## Explore the impact of different models based on cross-language training


### Group1: Training Hungarian dataset based on conformer and fast-conformer model

Conference1: [Sigul2023](https://sigul-2023.ilc.cnr.it/wp-content/uploads/2023/08/25_Paper.pdf) \
What kind of multi- or cross-lingual pre-training is the most effective for a
spontaneous, less-resourced ASR task? \
Journal1: (that I will submit)

In my research, I confirmed that using the English pre-trained Conformer model to train 
the Hungarian dataset (BEA-Base) can achieve higher accuracy. 
At the same time, if fast-conformer pre-trained model is used for training, similar results can be obtained 
in a shorter time and with less GPU memory consumption.
![img.png](sigul2023.png)

Conference2: InterSpeech2024(Submitted) \
On Disfluency and Non-lexical Sound Labeling for End-to-end Automatic
Speech Recognition \




### Group2: Training Hungarian dataset based on Whisper model

